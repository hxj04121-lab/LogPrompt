Baseline 模型开源代码复现指南这份文档旨在帮助你快速定位并复现 LogGPT、LogPrompt 和 RAGLog 这三个核心 Baseline 模型。1
. LogGPT: Log-Based Anomaly Detection via GPT论文: LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection开源代码仓库:官
方仓库: https://github.com/nokia/LogGPT (Star 数: ~120)备用/相关仓库: 也有研究者在 LogIntelligence 等组织下发布过复现，但 Nokia 官方仓库是最权威的。核心复现步骤环境配置:该项目通常基于 PyTorch 和 Transformers 库。你需要安装 requirements.txt 中的依赖。数据准备:项目通常支持 HDFS, BGL, Thunderbird 三大数据集。关键点: 你需要先运行数据预处理脚本（通常是 data_process.py 或类似），将原始日志转换为 LogGPT 需要的 Session Window (会话窗口) 或 Fixed Window (固定窗口) 序列格式。提示: LogGPT 需要的是 (Input Sequence, Next Log Key) 格式的数据用于训练。运行训练 (Pre-training):运行 main.py 或 train.py。核心参数：--dataset HDFS (指定数据集)。这个阶段模型学习预测下一个日志模版。运行微调 (Fine-tuning / Reinforcement Learning):LogGPT 的一个亮点是使用了强化学习 (RL) 进行微调。你需要查看代码中关于 RL 的部分（通常会有 flag 如 --use_rl）。评估 (Evaluation):运行评估脚本，它会计算 Top-K 准确率，或者在异常检测任务上计算 F1-Score。
2. LogPrompt: Zero-Shot Log Analysis with Prompt Engineering论文: LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis开源代码仓库:
官方仓库: https://github.com/lunyiliu/LogPrompt (Star 数: ~50)注意: 这是一个基于 Prompt Engineering 的项目，所以它的核心不是训练代码，而是 Prompt 构建脚本 和 API 调用逻辑。核心复现步骤准备 LLM API:你需要一个 OpenAI API Key，或者准备一个本地部署的 LLM (如 Llama 3) 并通过 API 暴露（例如使用 Ollama 或 vLLM）。
提示: 为了节省成本，复现时可以先用少量数据测试。查看 Prompt 模板:在代码中找到存放 Prompt 的文件（通常是 prompts.py 或 templates/ 目录）。核心复现点: 仔细阅读其中的 CoT (Chain-of-Thought) 模板，看看它是如何引导模型一步步分析日志的。运行推理:运行主脚本（如 run_logprompt.py）。脚本会读取日志文件，拼接 Prompt，发送给 LLM，然后解析 LLM 的返回结果（Normal/Anomaly）。指标计算:LogPrompt 的输出通常是文本。你需要写一个小脚本，将 LLM 输出的 "Anomaly" 文本转换为标签 1，"Normal" 转换为 0，然后与真实标签对比计算 F1。3. RAGLog: Log Anomaly Detection using RAG论文: RAGLog: Log Anomaly Detection using Retrieval Augmented Generation开源代码仓库:官方/非官方复现状态: 该论文目前没有官方的 GitHub 仓库链接直接附在论文中。替代方案 (RAGPrompt): 社区有一个非常高质量的复现项目叫 RAGPrompt，它实现了 RAG + Log 的核心思想，非常适合作为 RAGLog 的替代 Baseline。RAGPrompt 仓库: https://github.com/gypark94/RAGpromptRAGPrompt (作为 RAGLog 替代) 复现步骤安装依赖:该项目主要依赖 LangChain 和向量数据库 (如 Chroma 或 FAISS)。构建知识库 (Indexing):这是 RAG 的核心。你需要运行脚本，将正常日志 (Normal Logs) 切分、Embedding 并存入向量数据库。提示: 可以尝试使用不同的 Embedding 模型（如 all-MiniLM-L6-v2）来测试效果。配置 RAG 链:代码中会有一个 RAG Chain 的定义。它会执行：检索 -> 增强 Prompt -> LLM 生成。你需要检查它的 Prompt Template，确保它包含了“请根据检索到的参考日志判断...”这样的指令。运行检测:将测试集日志输入系统。系统会去知识库检索，然后 LLM 给出判断。总结：你的 Baseline 复现清单模型仓库地址核心技术复现难度备注LogGPTnokia/LogGPTFine-tuning (GPT)中等需 GPU 训练LogPromptlunyiliu/LogPromptZero-shot CoT简单需 API KeyRAGLoggypark94/RAGprompt (替代)RAG (Retrieval)中等需构建向量库建议你先从 LogPrompt 开始，因为它不需要训练，环境配置最简单。然后尝试 RAGPrompt (代表 RAGLog)，最后如果有余力再复现 LogGPT。
